{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZYQpDkInsVt"
      },
      "outputs": [],
      "source": [
        "# El dataset cuenta con estas images\n",
        "\n",
        "<userid> <pose> <expression> <eyes> <scale>.pgm\n",
        "<userid> is the user id of the person in the image, and this field has 20 values: an2i, at33, boland, bpm, ch4f, cheyer, choon, danieln, glickman, karyadi, kawamura, kk49, megak, mitchell, night, phoebe, saavik, steffi, sz24, and tammo.\n",
        "<pose> is the head position of the person, and this field has 4 values: straight, left, right, up.\n",
        "<expression> is the facial expression of the person, and this field has 4 values: neutral, happy, sad, angry.\n",
        "<eyes> is the eye state of the person, and this field has 2 values: open, sunglasses.\n",
        "<scale> is the scale of the image, and this field has 3 values: 1, 2, and 4. 1 indicates a full-resolution image (128 columns by 120 rows); 2 indicates a half-resolution image (64 by 60); 4 indicates a quarter-resolution image (32 by 30).\n",
        "If you've been looking closely in the image directories, you may notice that some images have a .bad suffix rather than the .pgm suffix. As it turns out, 16 of the 640 images taken have glitches due to problems with the camera setup; these are the .bad images. Some people had more glitches than others, but everyone who got ``faced'' should have at least 28 good face images (out of the 32 variations possible, discounting scale)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_-p86T2n2KH"
      },
      "source": [
        " **Nombre de los integrantes:**\n",
        "\n",
        "\n",
        "* **Integrante 1:** Juan José Monsalve Patiño \\\\\n",
        "* **Integrante 2:** Pamela Escobar Palacios \\\\\n",
        "* **Integrante 3:** José Julián Aguirre Ramírez \\\\\n",
        "* **Integrante 4:** Santiago Mejia Carmona\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhVrFqatoHvv"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://blogs.elespectador.com/wp-content/uploads/2017/09/logo-Universidad-Nacional.png\" width=\"500\" alt=\"logo\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyauN4RUoSZ9"
      },
      "source": [
        "**Definición del problema**\n",
        "\n",
        "DEFINIR EL PROBLEMA ---- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1Na9Knooj6"
      },
      "source": [
        "## Instalar librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401HEUBwonZy",
        "outputId": "9b23864a-befe-476f-f7ad-dce7fd4cb30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "from keras.utils import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import os\n",
        "import seaborn as sns\n",
        "from skimage import feature, io\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skimage.feature import hog\n",
        "import random\n",
        "import itertools\n",
        "from shutil import copyfile, rmtree\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWgd6xcIpkcR"
      },
      "source": [
        "# Análisis descriptivo y exploratorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAa-pOl9pt57",
        "outputId": "0658c916-33a8-47e8-d975-c2256df8e97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se cuentan con 0 sin gafas\n",
            "--------------------------------------------------------------\n",
            "Se cuentan con 0 con gafas\n"
          ]
        }
      ],
      "source": [
        "sin_gafas = '/content/drive/MyDrive/imagenes_analitica/con_gafas'\n",
        "con_gafas = '/content/drive/MyDrive/imagenes_analitica/sin_gafas'\n",
        "print('Se cuentan con', len(os.listdir(sin_gafas)), 'sin gafas')\n",
        "print('--------------------------------------------------------------')\n",
        "print('Se cuentan con', len(os.listdir(con_gafas)), 'con gafas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH-LUCW8ww7n"
      },
      "source": [
        "#Cargar y Preprocesar Imágenes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DEzJcv27xrj3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from skimage import io, color, transform\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Directorio que contiene las carpetas con gafas y sin gafas\n",
        "dataset_dir = '/content/drive/MyDrive/imagenes_analitica'\n",
        "\n",
        "# Cargar imágenes y etiquetas\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label, category in enumerate(['con_gafas', 'sin_gafas']):\n",
        "    category_dir = os.path.join(dataset_dir, category)\n",
        "    for filename in os.listdir(category_dir):\n",
        "        img_path = os.path.join(category_dir, filename)\n",
        "        img = io.imread(img_path)\n",
        "        img = transform.resize(img, (64, 64, 3)).flatten()  # Ajusta el tamaño según sea necesario\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrITtvla7EnC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDeNFnPH0Y2m"
      },
      "source": [
        " # Construir y Entrenar el Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFHAXRwX0dR1",
        "outputId": "dad5d2a0-4517-45ca-e66b-db98212f63c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 17s 1s/step - loss: 11.6016 - accuracy: 0.4689 - val_loss: 6.1543 - val_accuracy: 0.4320\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 16s 1s/step - loss: 2.1524 - accuracy: 0.5651 - val_loss: 1.5810 - val_accuracy: 0.5760\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 16s 1s/step - loss: 1.1804 - accuracy: 0.5972 - val_loss: 0.5913 - val_accuracy: 0.7280\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.7365 - accuracy: 0.6593 - val_loss: 0.5155 - val_accuracy: 0.7920\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 15s 979ms/step - loss: 0.5913 - accuracy: 0.7154 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 14s 897ms/step - loss: 0.6079 - accuracy: 0.6954 - val_loss: 0.6030 - val_accuracy: 0.6720\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 15s 888ms/step - loss: 0.6152 - accuracy: 0.6834 - val_loss: 0.5899 - val_accuracy: 0.7280\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 16s 952ms/step - loss: 0.5764 - accuracy: 0.7295 - val_loss: 0.4718 - val_accuracy: 0.8080\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 16s 998ms/step - loss: 0.4562 - accuracy: 0.7976 - val_loss: 0.4686 - val_accuracy: 0.8160\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.4468 - accuracy: 0.8016 - val_loss: 0.4308 - val_accuracy: 0.8240\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cbe09af1120>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# las imágenes son en escala de grises y aplanadas (64x64x3)\n",
        "model = models.Sequential([\n",
        "    layers.Dense(4096, activation='relu', input_shape=(64*64*3,)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HjFS24W3QQK"
      },
      "source": [
        "# Pruebas del Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wA4Qvxp3TI4",
        "outputId": "4a1a1d08-562b-483d-c5f3-171a5d9c9f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 90ms/step\n",
            "Accuracy: 0.824\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.84        71\n",
            "           1       0.78      0.83      0.80        54\n",
            "\n",
            "    accuracy                           0.82       125\n",
            "   macro avg       0.82      0.83      0.82       125\n",
            "weighted avg       0.83      0.82      0.82       125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Suponiendo que ya has entrenado tu modelo y tienes X_test y y_test listos.\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convertir las predicciones a clases binarias (0 o 1) según un umbral (por ejemplo, 0.5)\n",
        "threshold = 0.5\n",
        "predicted_classes = (predictions > threshold).astype(int)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(y_test, predicted_classes)\n",
        "report = classification_report(y_test, predicted_classes)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
